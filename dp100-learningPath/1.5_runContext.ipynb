{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3-azureml",
   "display_name": "Python 3.6 - AzureML",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.core import Workspace\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "from azureml.core.environment import CondaDependencies\n",
    "from sklearn import datasets\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "#create an experiment variable\n",
    "experiment = Experiment(workspace=ws, name=\"my-experiment\")\n",
    "\n",
    "#start the experiment\n",
    "run = experiment.start_logging()\n",
    "\n",
    "#experiment code goes here\n",
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(data=iris['data'], columns=iris['feature_names'])\n",
    "row_count = df.shape[0] #eksperimentet som gjøres\n",
    "\n",
    "\n",
    "#Logger row_count'en\n",
    "run.log('observations', row_count) #Denne finner du i aml studio under Experiments\n",
    "\n",
    "\n",
    "#end experiment\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7bf8a4d847c643258c6e2304a80f348b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/my-experiment/runs/5299ed5e-4fe2-4382-ac2f-6cfe8badd1ef?wsid=/subscriptions/30fb7505-9731-4f44-bc63-4d5cd1278bf0/resourcegroups/mlcourserg/workspaces/mlcourse\", \"run_id\": \"5299ed5e-4fe2-4382-ac2f-6cfe8badd1ef\", \"run_properties\": {\"run_id\": \"5299ed5e-4fe2-4382-ac2f-6cfe8badd1ef\", \"created_utc\": \"2021-02-19T07:20:15.563612Z\", \"properties\": {\"ContentSnapshotId\": \"6636a0fd-d4f7-4223-95be-4f0679a184ae\"}, \"tags\": {}, \"end_time_utc\": \"2021-02-19T07:20:16.688353Z\", \"status\": \"Completed\", \"log_files\": {}, \"log_groups\": [], \"run_duration\": \"0:00:01\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"observations\", \"run_id\": \"5299ed5e-4fe2-4382-ac2f-6cfe8badd1ef\", \"categories\": [0], \"series\": [{\"data\": [150]}]}], \"run_logs\": \"\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.20.0\"}, \"loading\": false}"
     },
     "metadata": {}
    }
   ],
   "source": [
    "RunDetails(run).show()\n",
    "\n",
    "#Generate output files - e.g. trained ML models\n",
    "#run.upload_file(name='outputs/sample.csv', path_or_stream='./sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Attempted to log scalar metric observations:\n150\n"
     ]
    }
   ],
   "source": [
    "#Det er vanligst å encapsulate eksperiment logikkk i et script, og kjøre scriptet som eksperimentet.\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Get the experiment run context\n",
    "experiment = Experiment(workspace=ws, name=\"my-experiment\")\n",
    "\n",
    "#start the experiment\n",
    "run = experiment.start_logging()\n",
    "run = Run.get_context() #Bruker denne for å logge metrikker, uploade filer og fullføre eksperimentet\n",
    "\n",
    "# load the diabetes dataset\n",
    "data = df\n",
    "\n",
    "# Count the rows and log the result\n",
    "row_count = (len(data))\n",
    "run.log('observations', row_count)\n",
    "\n",
    "# Save a sample of the data\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "data.sample(100).to_csv(\"outputs/sample.csv\", index=False, header=True)\n",
    "\n",
    "# Complete the run\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'experiment_folder' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1c71347a46c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Create a script config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m script_config = ScriptRunConfig(source_directory=experiment_folder,\n\u001b[0m\u001b[1;32m      5\u001b[0m                                 script='experiment.py') \n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'experiment_folder' is not defined"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig\n",
    "\n",
    "# Create a script config\n",
    "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
    "                                script='experiment.py') \n",
    "\n",
    "# submit the experiment\n",
    "experiment = Experiment(workspace = ws, name = 'my-experiment')\n",
    "run = experiment.submit(config=script_config)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}